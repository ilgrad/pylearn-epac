#!/usr/bin/python3

# -*- coding: utf-8 -*-
"""
Created on Wed Apr 24 11:18:19 2013

@author: edouard.duchesnay@cea.fr
@author: benoit.da_mota@inria.fr
@author: jinpeng.li@cea.fr
"""

import sys
import os
import optparse
import numpy as np
from epac import conf, StoreFs, MapperSubtrees
from epac.map_reduce.inputs import NodesInput
from epac.map_reduce.engine import SomaWorkflowEngine
from epac.utils import load_dataset
from epac.utils import trim_filepath
import joblib


if __name__ == "__main__":
    # parse command line options
    parser = optparse.OptionParser()
    parser.add_option('-d', '--datasets',
                      help='File path to ".npz" datasets called X.')
    parser.add_option('-f', '--format',
                      help='datasets format default numpy archive ".npz"')
    parser.add_option('-k', '--keys',
                      help='Key(s) of node(s) to be processed. ' + \
                      'You can put multiple keys using a separating sign ";".')
    parser.add_option('-s', '--keysfile',
                      help='Key(s) of node(s) to be processed. ' + \
                      'Those keys are saved in a file. Each line ' + \
                      'represents a key node')
    parser.add_option('-x', '--function',
                      help='Function to execute. Default "fit_predict"')
    parser.add_option('-m', '--mmap_mode',
                      help="{None, 'r+', 'r', 'w+', 'c', 'auto'} " + \
                      "'auto' means that the system determine " + \
                      "if we use memory mapping or not. " + \
                      "See numpy.load for the meaning of the other arguments.")
    parser.add_option('-t', '--treedir',
                      help='directory to save tree')
    # argv = ['epac_mapper',
    #         '--datasets',
    #         '/tmp/dataset',
    #         '--keysfile',
    #         '/tmp/workflow/./0.job',
    #         '--treedir',
    #         '/tmp/tree']
    # options, args = parser.parse_args(argv)
    # os.chdir("/tmp/tmp2HoBEk")
    options, args = parser.parse_args(sys.argv)
    # Set default values to parameters
    datasets_filepath = None
    datasets_format = "npz"
    keys = None
    listkey = list()
    function = "transform"
    mmap_mode = None

    if options.datasets:
        datasets_filepath = repr(options.datasets)
        # To remove quote signs in the path
        datasets_filepath = trim_filepath(datasets_filepath)
    else:
        raise ValueError("key(s) is not provided use: --datasets")

    if options.format:
        datasets_format = repr(options.format)

    if options.keys:
        keys = repr(options.keys)
        # To remove quote sisgns in the path
        keys = keys.replace("'", '')
        keys = keys.replace('"', '')
        listkey = keys.split(";")
    elif options.keysfile:
        relative_filepath = options.keysfile
        relative_filepath = trim_filepath(relative_filepath)
        key_lines = None
        f = open(relative_filepath, 'r')
        key_lines = f.readlines()
        f.close()
        if key_lines:
            for key_line in key_lines:
                key_line = trim_filepath(key_line)
                listkey.append(key_line)
    else:
        raise ValueError("key(s) is not provided use: --key")

    if options.function:
        function = repr(options.function)

    if len(listkey) <= 0:
        sys.exit(0)

    if options.mmap_mode:
        mmap_mode = options.mmap_mode

    nodes_input = NodesInput(listkey[0])
    for str_key in listkey:
        nodes_input.add(str_key)

    # Load datasets
    # print "datasets_filepath:", datasets_filepath
    # print "keys:", keys
    # datasets_filepath = "/tmp/tmpZ2HqYb_datasets.npz"
    # datasets_filepath ="/tmp/tmpO8D3dG_datasets.npz"
    # keys="fs:///tmp/tmpXyC_XE/ParPerm/Perm(nb=0)"

    Xy = load_dataset(datasets_filepath, mmap_mode)

    tree_root_relative_path = SomaWorkflowEngine.tree_root_relative_path
    if options.treedir:
        tree_root_relative_path = options.treedir
        tree_root_relative_path = trim_filepath(tree_root_relative_path)

    store_fs = StoreFs(tree_root_relative_path)
    tree = store_fs.load(key=conf.STORE_EXECUTION_TREE_PREFIX)

    mapper_subtrees = MapperSubtrees(Xy=Xy,
                                     tree_root=tree,
                                     store_fs=store_fs,
                                     function=function)
    tree = mapper_subtrees.map(nodes_input)
